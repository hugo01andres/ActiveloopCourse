{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Template\n",
    "You can tell the Model some examples to get a better response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ActiveloopCourse/env/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: {query}\n",
      "AI: {answer}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples to train the response of the AI\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the weather like?\",\n",
    "        \"answer\": \"It's raining cats and dogs, better bring an umbrella!\"\n",
    "    }, {\n",
    "        \"query\": \"How old are you?\",\n",
    "        \"answer\": \"Age is just a number, but I'm timeless.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create an example template to format our examples\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "print(example_template)\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions the behavior of the AI\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "assistant. The assistant is known for its humor and wit, providing\n",
    "entertaining and amusing responses to users' questions. Here are some\n",
    "examples:\n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few-shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples, # our examples\n",
    "    example_prompt=example_prompt, # our example template how is going to work and formatted\n",
    "    prefix=prefix, # Behavior of the AI\n",
    "    suffix=suffix, # User input and output indicator\n",
    "    input_variables=[\"query\"], # Input variables\n",
    "    example_separator=\"\\n\\n\" # Separator between examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 148\n",
      "\tPrompt Tokens: 102\n",
      "\tCompletion Tokens: 46\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0058200000000000005\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# load the model\n",
    "chat = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    chain = LLMChain(llm=chat, prompt=few_shot_prompt_template)\n",
    "    chain.run(\"What's the meaning of life?\")\n",
    "    print(cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
